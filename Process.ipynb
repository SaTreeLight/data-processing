{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2da17f2d-d88c-4f46-9ec5-6b0b57111d7f",
    "deepnote_cell_height": 746,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 41378,
    "execution_start": 1650741006273,
    "source_hash": "782e1a64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install geojson sentinelhub numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-71909d8c-14dd-4b27-9421-05cbcdce445d",
    "deepnote_cell_height": 766.375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7111,
    "execution_start": 1650741047697,
    "id": "kTztz5yuFarE",
    "source_hash": "54502e38"
   },
   "outputs": [],
   "source": [
    "# Import block\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(\n",
    "    linewidth=160, precision=2, suppress=True, floatmode=\"maxprec_equal\"\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numba import njit, prange\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "# Remove annoying deprecation warnings\n",
    "warnings.simplefilter(\"ignore\", category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "from enum import IntEnum\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import geojson\n",
    "from sentinelhub import (\n",
    "    DataCollection,\n",
    "    SHConfig,\n",
    "    SentinelHubRequest,\n",
    "    MimeType,\n",
    "    bbox_to_dimensions,\n",
    "    Geometry,\n",
    "    BBoxSplitter,\n",
    "    BBox,\n",
    "    CRS,\n",
    ")\n",
    "\n",
    "import glob, os\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-b1ed23e1-6fe9-4e79-8b7f-b75f09fd1ec9",
    "deepnote_cell_height": 1683,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1650741054860,
    "id": "5ICcrJA9y88Y",
    "source_hash": "b503754a"
   },
   "outputs": [],
   "source": [
    "# Bands constants\n",
    "class Bands(IntEnum):\n",
    "    L = 1  # Grayscale\n",
    "    LA = 2  # Grayscale w/Alpha\n",
    "    RGB = 3  # Red, Green, Blue\n",
    "    RGBA = 4  # Red, Green, Blue, Alpha\n",
    "\n",
    "\n",
    "# Dataset constants\n",
    "class Dataset:\n",
    "    NDVI = \"NDVI\"\n",
    "    TRUECOLOR = \"TRUECOLOR\"\n",
    "    SWIR = \"SWIR\"\n",
    "\n",
    "\n",
    "# Returns the sentinelrequest evalscript stirng to download \n",
    "# the specified dataset\n",
    "def evalscript(dataset, bands):\n",
    "    if dataset == Dataset.NDVI:\n",
    "        return \"\"\"\n",
    "            //VERSION=3\n",
    "\n",
    "            let viz = ColorMapVisualizer.createDefaultColorMap();\n",
    "\n",
    "            function evaluatePixel(samples) {\n",
    "                let val = index(samples.B08, samples.B04);\n",
    "                val = viz.process(val);\n",
    "                val.push(samples.dataMask);\n",
    "                return val;\n",
    "            } \n",
    "\n",
    "            function setup() {\n",
    "                return {\n",
    "                input: [{\n",
    "                    bands: [\n",
    "                    \"B04\",\n",
    "                    \"B08\",\n",
    "                    \"dataMask\"\n",
    "                    ]\n",
    "                }],\n",
    "                output: {\n",
    "                    bands: %d }\n",
    "                }\n",
    "            }\n",
    "            \"\"\" % (\n",
    "            bands\n",
    "        )\n",
    "    elif dataset == Dataset.TRUECOLOR:\n",
    "        return \"\"\"\n",
    "            //VERSION=3\n",
    "            let minVal = 0.0;\n",
    "            let maxVal = 0.4;\n",
    "\n",
    "            let viz = new HighlightCompressVisualizer(minVal, maxVal);\n",
    "\n",
    "            function setup() {\n",
    "            return {\n",
    "                input: [\"B04\", \"B03\", \"B02\",\"dataMask\"],\n",
    "                output: { bands: %d }\n",
    "            };\n",
    "            }\n",
    "\n",
    "            function evaluatePixel(samples) {\n",
    "                let val = [samples.B04, samples.B03, samples.B02,samples.dataMask];\n",
    "                return viz.processList(val);\n",
    "            }\"\"\" % (\n",
    "            bands\n",
    "        )\n",
    "    elif dataset == Dataset.SWIR:\n",
    "        return \"\"\"\n",
    "            //VERSION=3\n",
    "            let minVal = 0.0;\n",
    "            let maxVal = 0.4;\n",
    "\n",
    "            let viz = new HighlightCompressVisualizer(minVal, maxVal);\n",
    "\n",
    "            function setup() {\n",
    "            return {\n",
    "                input: [\"B12\", \"B8A\", \"B04\",\"dataMask\"],\n",
    "                output: { bands: %d }\n",
    "            };\n",
    "            }\n",
    "\n",
    "            function evaluatePixel(samples) {\n",
    "                let val = [samples.B12, samples.B8A, samples.B04,samples.dataMask];\n",
    "                return viz.processList(val);\n",
    "            } \"\"\" % (\n",
    "            bands\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-938a00b0-a6fa-44c8-8c64-28cd806a9d30",
    "deepnote_cell_height": 1233,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 521282704,
    "execution_start": 1650741054916,
    "id": "c1M0Bp8Fiv4j",
    "source_hash": "68a8d2ae"
   },
   "outputs": [],
   "source": [
    "# Download image from sentinelhub, bounded by the border polygon,resolution given by bbox size\n",
    "def download_image(\n",
    "    bbox_size,\n",
    "    border_polygon,\n",
    "    data_folder,\n",
    "    time_interval=\"latest\",\n",
    "    dataset=Dataset.TRUECOLOR,\n",
    "    bands=Bands.RGBA,\n",
    "    bbox=None,\n",
    "    format=\"png\",\n",
    "    save_data=True,\n",
    "    redownload=False,\n",
    "):\n",
    "    # User ID\n",
    "    CLIENT_ID = \"put-your-sentinel-hub-id-here\"\n",
    "    CLIENT_SECRET = \"put-your-sentinel-hub-id-here\"\n",
    "\n",
    "    config = SHConfig()\n",
    "\n",
    "    if CLIENT_ID and CLIENT_SECRET:\n",
    "        config.sh_client_id = CLIENT_ID\n",
    "        config.sh_client_secret = CLIENT_SECRET\n",
    "\n",
    "    if config.sh_client_id == \"\" or config.sh_client_secret == \"\":\n",
    "        print(\n",
    "            \"Warning! To use Sentinel Hub services, please provide the credentials (client ID and client secret).\"\n",
    "        )\n",
    "\n",
    "    # Set image format, png has smaller file size than tiff\n",
    "    img_format = MimeType.PNG\n",
    "    if format == \"tiff\":\n",
    "        img_format = MimeType.TIFF\n",
    "\n",
    "    # Find latest data with low cloud coverage\n",
    "    input_data = [\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L2A,\n",
    "            maxcc=0.01,\n",
    "        )\n",
    "    ]\n",
    "    # Find data in specified date interval\n",
    "    if time_interval != \"latest\":\n",
    "        input_data = [\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                time_interval=time_interval,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Make the data request\n",
    "    sentinel_request = SentinelHubRequest(\n",
    "        evalscript=evalscript(dataset, bands),\n",
    "        input_data=input_data,\n",
    "        responses=[\n",
    "            SentinelHubRequest.output_response(\"default\", img_format),\n",
    "        ],\n",
    "        bbox=bbox,\n",
    "        size=bbox_size,\n",
    "        geometry=border_polygon,\n",
    "        config=config,\n",
    "        data_folder=data_folder,\n",
    "    )\n",
    "    # Return the data of the request, use cached if available\n",
    "    return sentinel_request.get_data(save_data=save_data, redownload=redownload)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-f77eb51b-1230-49b1-b93b-b0a181ea59c0",
    "deepnote_cell_height": 2997,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 73,
    "execution_start": 1650741054988,
    "id": "mvnA--QDTKhW",
    "source_hash": "60e3ae59"
   },
   "outputs": [],
   "source": [
    "# Get the image of the area specified by the geojson with the given filename.\n",
    "# The image may be split in tiles due to large size but can be stitched to one image.\n",
    "def get_image(\n",
    "    filename,\n",
    "    dataset=Dataset.TRUECOLOR,\n",
    "    bands=Bands.RGBA,\n",
    "    time_interval=\"\",\n",
    "    stitch_tiles=False,\n",
    "    format=\"png\",\n",
    "    force_download=False,\n",
    "    debug=False,\n",
    "):\n",
    "    # Extract city name\n",
    "    city_name = filename.split(\"/\")[-1].split(\".json\")[0]    \n",
    "    # Look for existing image, make its folder if missing\n",
    "    data_folder = \"Images/{:s}/{:s} {:s} {:n}\".format(\n",
    "        city_name, city_name, dataset, bands\n",
    "    )\n",
    "\n",
    "    stitched_image_filename = \"Images/{:s}/{:s} {:s} {:n}.{:s}\".format(\n",
    "        city_name, city_name, dataset, bands, format\n",
    "    )\n",
    "    if stitch_tiles and os.path.exists(stitched_image_filename) and not force_download:\n",
    "        return Image.open(stitched_image_filename)\n",
    "\n",
    "    # Open the geojson file and extract the polygon(s)\n",
    "    with open(filename) as file:\n",
    "        shapefile = geojson.load(file)\n",
    "        if \"geometries\" in shapefile.keys():\n",
    "            polygon = shapefile[\"geometries\"][0]\n",
    "        else:\n",
    "            polygon = shapefile\n",
    "\n",
    "        # Find a specified time interval, if there is one\n",
    "        if \"timeInterval\" in shapefile.keys():\n",
    "            time_interval = (\n",
    "                shapefile[\"timeInterval\"][\"startTime\"],\n",
    "                shapefile[\"timeInterval\"][\"endTime\"],\n",
    "            )\n",
    "        elif time_interval == \"\":\n",
    "            time_interval = \"latest\"\n",
    "\n",
    "        # Make the bounding box (bbox) of the polygon\n",
    "        city_geometry = Geometry.from_geojson(polygon, crs=CRS.WGS84)\n",
    "        city_bbox = city_geometry.bbox\n",
    "        # Figure out the image dimensions for 10 meters per pixel\n",
    "        city_bbox_size = bbox_to_dimensions(city_bbox, 10)\n",
    "\n",
    "    # Download a single image if the dimensions are small enough\n",
    "    if not (city_bbox_size[0] > 2500 or city_bbox_size[1] > 2500):\n",
    "        if debug:\n",
    "            print(city_bbox_size)\n",
    "        # Download the image/load it from cache\n",
    "        data = download_image(\n",
    "            city_bbox_size,\n",
    "            city_geometry,\n",
    "            data_folder,\n",
    "            time_interval=time_interval,\n",
    "            dataset=dataset,\n",
    "            bands=bands,\n",
    "            format=format,\n",
    "            redownload=force_download,\n",
    "        )\n",
    "        image = Image.fromarray(data)\n",
    "        if stitch_tiles:\n",
    "            # Save the image with a more descriptive filename, easier acess\n",
    "            image.save(stitched_image_filename)\n",
    "        return image\n",
    "\n",
    "    # If the dimensions are too large: Divide the image into a grid of tiles, and download\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"Too large: \", city_bbox_size)\n",
    "        # Find the number of tiles in both directions, add small buffer to size in division\n",
    "        height = int(np.ceil(city_bbox_size[0] / 2480))\n",
    "        width = int(np.ceil(city_bbox_size[1] / 2480))\n",
    "        if debug:\n",
    "            print(\"Splitting to {:n}x{:n} grid.\".format(width, height))\n",
    "\n",
    "        # Split the boundary box into a grid\n",
    "        bboxes = city_geometry.bbox.get_partition(num_x=height, num_y=width)\n",
    "        if debug:\n",
    "            print(bboxes)\n",
    "\n",
    "        # Because the dimensions of the tiles might vary by a few pixels (~10-20) because of the map projection,\n",
    "        # we find the average tile dimensions. This is done to make the stitching\n",
    "        # of the tiles seamless. The distortion (difference in resolution) is negligible, as we're\n",
    "        # typically dealing with less than 1% difference from 10 m.\n",
    "        cumulative_dim = [0, 0]\n",
    "        for i, bbox_col in enumerate(bboxes):\n",
    "            for j, bbox in enumerate(bbox_col):\n",
    "                dims = bbox_to_dimensions(bbox, 10)\n",
    "                cumulative_dim[0] += dims[0]\n",
    "                cumulative_dim[1] += dims[1]\n",
    "                if debug:\n",
    "                    print(dims)\n",
    "        num_bbox = (i + 1) * (j + 1)\n",
    "        avg_dim = (int(cumulative_dim[0] / num_bbox), int(cumulative_dim[1] / num_bbox))\n",
    "        if debug:\n",
    "            print(avg_dim)\n",
    "\n",
    "        if stitch_tiles:        \n",
    "            # Prepare the array for the stitched tiles\n",
    "            if bands == 1:\n",
    "                stitched_image = np.full(\n",
    "                    (avg_dim[1] * width, avg_dim[0] * height),\n",
    "                    fill_value=np.nan,\n",
    "                    dtype=np.uint8,\n",
    "                )\n",
    "            else:\n",
    "                stitched_image = np.full(\n",
    "                    (avg_dim[1] * width, avg_dim[0] * height, bands),\n",
    "                    fill_value=np.nan,\n",
    "                    dtype=np.uint8,\n",
    "                )\n",
    "\n",
    "        # List to contain the separate images, this will be returned if stitching is disabled\n",
    "        images = []\n",
    "        # Set up progressbar to keep track of the downloads\n",
    "        pbar = tqdm(\n",
    "            total=width * height,\n",
    "            desc=\"Downloading {:s} {:s}\".format(city_name, dataset),\n",
    "            leave=False,\n",
    "        )\n",
    "        # Go through each bbox and download the image\n",
    "        for x, row in enumerate(bboxes):\n",
    "            for y, bbox in enumerate(row):\n",
    "                if debug:\n",
    "                    print(y, x)\n",
    "                tile = download_image(\n",
    "                    avg_dim,\n",
    "                    city_geometry,\n",
    "                    data_folder,\n",
    "                    time_interval=time_interval,\n",
    "                    dataset=dataset,\n",
    "                    bands=bands,\n",
    "                    bbox=bbox,\n",
    "                    format=format,\n",
    "                    redownload=force_download,\n",
    "                )\n",
    "                images.append(Image.fromarray(tile))\n",
    "                if stitch_tiles:\n",
    "                    # Add the tile to its corresponding place in the large stitched array\n",
    "                    if bands == 1:\n",
    "                        stitched_image[\n",
    "                            (width - 1 - y) * avg_dim[1] : (width - y) * avg_dim[1],\n",
    "                            (x) * avg_dim[0] : (x + 1) * avg_dim[0],\n",
    "                        ] = tile\n",
    "                    else:\n",
    "                        stitched_image[\n",
    "                            (width - 1 - y) * avg_dim[1] : (width - y) * avg_dim[1],\n",
    "                            (x) * avg_dim[0] : (x + 1) * avg_dim[0],\n",
    "                            :,\n",
    "                        ] = tile\n",
    "                pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "        if stitch_tiles:\n",
    "            # Save the stitched image, set the returning images to the stitched one\n",
    "            images = Image.fromarray(stitched_image)\n",
    "            images.save(stitched_image_filename)\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b718e04e82b64980a77ed65b90fbdb2d",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 44,
    "execution_start": 1650219772245,
    "is_code_hidden": true,
    "source_hash": "f2a6c375",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Highlights the vegetation in the true color image, also returns the vegetation fraction\n",
    "def highlight_vegetation(\n",
    "    image_NDVI, image_TRUECOLOR, bands=Bands.RGBA, highlight_color=(0, 255, 0, 255)\n",
    "):\n",
    "    # Convert images to arrays that numba can do calculations on, PIL images directly don't work\n",
    "    shape = (image_NDVI.size[1], image_NDVI.size[0], bands)\n",
    "    data_NDVI = np.reshape(np.array(image_NDVI.getdata()), shape)\n",
    "    data_TRUECOLOR = np.reshape(np.array(image_TRUECOLOR.getdata()), shape)\n",
    "    # Get the resulting array and vegetation fraction from the calculation function\n",
    "    array, veg_frac, weight = highlight_vegetation_calc(\n",
    "        data_NDVI, data_TRUECOLOR, bands=bands\n",
    "    )\n",
    "    # Convert back to image and return it with the fraction\n",
    "    return Image.fromarray(np.array(array, dtype=np.uint8)), veg_frac, weight\n",
    "\n",
    "\n",
    "# Higher performance calculation function, utilizes numba to speed up, but is stricter on types\n",
    "@njit\n",
    "def highlight_vegetation_calc(\n",
    "    image_NDVI, image_TRUECOLOR, bands=Bands.RGBA, highlight_color=(0, 255, 0, 255)\n",
    "):\n",
    "    (height, width, _bands) = np.shape(image_NDVI)\n",
    "\n",
    "    # Colors in NDVI that corresponds to vegetation\n",
    "    green_encodings = [\n",
    "        (51, 204, 204, 255),\n",
    "        (0, 102, 102, 255),\n",
    "        (51, 255, 51, 255),\n",
    "        (51, 204, 51, 255),\n",
    "        (0, 102, 0, 255),\n",
    "    ]\n",
    "\n",
    "    # Color that corresponds to water\n",
    "    water_encoding = (0, 0, 0, 255)\n",
    "\n",
    "    # Pixel counters to calculate vegetation fraction\n",
    "    total_valid_pixels = 0\n",
    "    total_green_pixels = 0\n",
    "\n",
    "    # Go through each pixel in image and highlight if vegetation\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel = image_NDVI[y, x]\n",
    "            # Make a comparable color tuple\n",
    "            pixel_tuple = (pixel[0], pixel[1], pixel[2], pixel[3])\n",
    "            if pixel_tuple in green_encodings:\n",
    "                # Change color of pixel to the highlight color, increase both counters\n",
    "                image_TRUECOLOR[y, x] = highlight_color\n",
    "                total_green_pixels += 1\n",
    "                total_valid_pixels += 1\n",
    "            elif pixel_tuple[-1] != 0 and pixel_tuple != water_encoding:\n",
    "                # If color is land, but not vegetation, increase total valid counter\n",
    "                total_valid_pixels += 1\n",
    "\n",
    "    # Return the highlighted image array, the vegetation fraction and the tile weight\n",
    "    if total_valid_pixels != 0:\n",
    "        return (\n",
    "            image_TRUECOLOR,\n",
    "            total_green_pixels / total_valid_pixels,\n",
    "            total_valid_pixels,\n",
    "        )\n",
    "    return image_TRUECOLOR, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0014643c6ed440e79fc0e63bba1f8575",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1650219772290,
    "is_code_hidden": true,
    "source_hash": "9171ae00",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filters out everything except vegetation from the truecolor image\n",
    "def vegetation_only(\n",
    "    image_NDVI, image_TRUECOLOR, bands=Bands.RGBA, highlight_color=(0, 0, 0, 0)\n",
    "):\n",
    "    # Convert images to arrays that numba can do calculations on, PIL images directly don't work\n",
    "    shape = (image_NDVI.size[1], image_NDVI.size[0], bands)\n",
    "    data_NDVI = np.reshape(np.array(image_NDVI.getdata()), shape)\n",
    "    data_TRUECOLOR = np.reshape(np.array(image_TRUECOLOR.getdata()), shape)\n",
    "    # Get the resulting array, vegetation fraction and tile weight from the calculation function\n",
    "    array, veg_frac, weight = vegetation_only_calc(\n",
    "        data_NDVI, data_TRUECOLOR, bands=bands, highlight_color=highlight_color\n",
    "    )\n",
    "    # Convert back to image and return it with the fraction and weight\n",
    "    return Image.fromarray(np.array(array, dtype=np.uint8)), veg_frac, weight\n",
    "\n",
    "\n",
    "# Higher performance calculation function, utilizes numba to speed up, but is stricter on types\n",
    "@njit\n",
    "def vegetation_only_calc(\n",
    "    image_NDVI, image_TRUECOLOR, bands=Bands.RGBA, highlight_color=(0, 0, 0, 0)\n",
    "):\n",
    "    height, width, bands = np.shape(image_NDVI)\n",
    "\n",
    "    # Colors in NDVI that corresponds to vegetation\n",
    "    green_encodings = [\n",
    "        (51, 204, 204, 255),\n",
    "        (0, 102, 102, 255),\n",
    "        (51, 255, 51, 255),\n",
    "        (51, 204, 51, 255),\n",
    "        (0, 102, 0, 255),\n",
    "    ]\n",
    "\n",
    "    # Color that corresponds to water\n",
    "    water_encoding = (0, 0, 0, 255)\n",
    "\n",
    "    # Pixel counters to calculate vegetation fraction\n",
    "    total_valid_pixels = 0\n",
    "    total_green_pixels = 0\n",
    "\n",
    "    # Go through each pixel in image and make transparent if not vegetation\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel = image_NDVI[y, x]\n",
    "            # Make a comparable color tuple\n",
    "            pixel_tuple = (pixel[0], pixel[1], pixel[2], pixel[3])\n",
    "            if pixel_tuple not in green_encodings and pixel_tuple[-1] != 0:\n",
    "                # Change color of pixel to the highlight color (transparent), increase total valid counter\n",
    "                image_TRUECOLOR[y, x] = highlight_color\n",
    "                total_valid_pixels += 1\n",
    "            elif pixel_tuple in green_encodings:\n",
    "                # If color is vegetation, increase both counters\n",
    "                total_green_pixels += 1\n",
    "                total_valid_pixels += 1\n",
    "            elif pixel_tuple[-1] != 0 and pixel_tuple != water_encoding:\n",
    "                # If color not transparent or water\n",
    "                total_valid_pixels += 1\n",
    "\n",
    "    # Return the highlighted image array, vegetation fraction and the tile weight\n",
    "    if total_valid_pixels != 0:\n",
    "        return (\n",
    "            image_TRUECOLOR,\n",
    "            total_green_pixels / total_valid_pixels,\n",
    "            total_valid_pixels,\n",
    "        )\n",
    "\n",
    "    return image_TRUECOLOR, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-131e24a6-55e1-4dc4-b47d-5262c14b6797",
    "deepnote_cell_height": 1341,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 149,
    "execution_start": 1650741055088,
    "owner_user_id": "b1fc138b-e9b1-4765-aed3-4877e4360e65",
    "source_hash": "c06267fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filters out everything except vegetation, and highlights the vegetation, also returns vegetation\n",
    "# fraction and tile weight\n",
    "def vegetation_only_highlighted(\n",
    "    image_NDVI, bands=Bands.RGBA, highlight_color=(0, 255, 0, 255)\n",
    "):\n",
    "    # Convert images to arrays that numba can do calculations on, PIL images directly don't work\n",
    "    shape = (image_NDVI.size[1], image_NDVI.size[0], bands)\n",
    "    data_NDVI = np.reshape(np.array(image_NDVI.getdata()), shape)\n",
    "    # Get the resulting array, vegetation fraction and tile weight from the calculation function\n",
    "    array, veg_frac, weight = vegetation_only_highlighted_calc(\n",
    "        data_NDVI, bands=bands, highlight_color=highlight_color\n",
    "    )\n",
    "    # Convert back to image and return it with the fraction and weight\n",
    "    return Image.fromarray(np.array(array, dtype=np.uint8)), veg_frac, weight\n",
    "\n",
    "\n",
    "# Higher performance calculation function, utilizes numba to speed up, but is stricter on types\n",
    "@njit\n",
    "def vegetation_only_highlighted_calc(\n",
    "    image_NDVI, bands=Bands.RGBA, highlight_color=(0, 255, 0, 255)\n",
    "):\n",
    "    height, width, bands = np.shape(image_NDVI)\n",
    "\n",
    "    # Colors in NDVI that corresponds to vegetation\n",
    "    green_encodings = [\n",
    "        (51, 204, 204, 255),\n",
    "        (0, 102, 102, 255),\n",
    "        (51, 255, 51, 255),\n",
    "        (51, 204, 51, 255),\n",
    "        (0, 102, 0, 255),\n",
    "    ]\n",
    "\n",
    "    # Color that corresponds to water\n",
    "    water_encoding = (0, 0, 0, 255)\n",
    "\n",
    "    # Transparent color\n",
    "    transparent = (0, 0, 0, 0)\n",
    "\n",
    "    # Pixel counters to calculate vegetation fraction\n",
    "    total_valid_pixels = 0\n",
    "    total_green_pixels = 0\n",
    "\n",
    "    # Go through each pixel in image and make transparent if not vegetation\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel = image_NDVI[y, x]\n",
    "            # Make a comparable color tuple\n",
    "            pixel_tuple = (pixel[0], pixel[1], pixel[2], pixel[3])\n",
    "            if pixel_tuple in green_encodings:\n",
    "                # If color is vegetation, increase both counters,\n",
    "                # highlight the vegetation\n",
    "                image_NDVI[y, x] = highlight_color\n",
    "                total_green_pixels += 1\n",
    "                total_valid_pixels += 1\n",
    "            elif pixel_tuple[-1] != 0 and pixel_tuple != water_encoding:\n",
    "                # If color not transparent or water, it's land\n",
    "                image_NDVI[y, x] = transparent\n",
    "                total_valid_pixels += 1\n",
    "            else:\n",
    "                # Filter out other water\n",
    "                image_NDVI[y, x] = transparent\n",
    "\n",
    "    # Return the highlighted image array, vegetation fraction and the tile weight\n",
    "    if total_valid_pixels != 0:\n",
    "        return (\n",
    "            image_NDVI,\n",
    "            total_green_pixels / total_valid_pixels,\n",
    "            total_valid_pixels,\n",
    "        )\n",
    "\n",
    "    return image_NDVI, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "49cb66c486ab4711bbddacf0377d2daa",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1650219772306,
    "is_code_hidden": true,
    "source_hash": "d5dea495",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the vegetation fraction and tile weight, but no returning image\n",
    "def veg_frac_only(image_NDVI, bands=Bands.RGBA):\n",
    "    # Convert image to an array that numba can do calculations on, PIL images directly don't work\n",
    "    shape = (image_NDVI.size[1], image_NDVI.size[0], bands)\n",
    "    data_NDVI = np.reshape(np.array(image_NDVI.getdata()), shape)\n",
    "    # Get the vegetation fraction and tile weight from the calculation function\n",
    "    veg_frac, weight = veg_frac_only_calc(data_NDVI)\n",
    "    return veg_frac, weight\n",
    "\n",
    "\n",
    "# Higher performance calculation function, utilizes numba to speed up, but is stricter on types\n",
    "@njit\n",
    "def veg_frac_only_calc(image_NDVI):\n",
    "    height, width, bands = np.shape(image_NDVI)\n",
    "\n",
    "    # Colors in NDVI that corresponds to vegetation\n",
    "    green_encodings = [\n",
    "        (51, 204, 204, 255),\n",
    "        (0, 102, 102, 255),\n",
    "        (51, 255, 51, 255),\n",
    "        (51, 204, 51, 255),\n",
    "        (0, 102, 0, 255),\n",
    "    ]\n",
    "\n",
    "    # Color that corresponds to water\n",
    "    water_encoding = (0, 0, 0, 255)\n",
    "\n",
    "    # Pixel counters to calculate vegetation fraction\n",
    "    total_valid_pixels = 0\n",
    "    total_green_pixels = 0\n",
    "\n",
    "    # Go through each pixel in image to find vegetation\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel = image_NDVI[y, x]\n",
    "            # Make a comparable color tuple\n",
    "            pixel_tuple = (pixel[0], pixel[1], pixel[2], pixel[3])\n",
    "            if pixel_tuple in green_encodings:\n",
    "                # Color is vegetation, increase both counters\n",
    "                total_green_pixels += 1\n",
    "                total_valid_pixels += 1\n",
    "            elif pixel_tuple[-1] != 0 and pixel_tuple != water_encoding:\n",
    "                # If color not transparent or water, it's land\n",
    "                total_valid_pixels += 1\n",
    "\n",
    "    # Return vegetation fraction and tile weight\n",
    "    if total_valid_pixels != 0:\n",
    "        return total_green_pixels / total_valid_pixels, total_valid_pixels\n",
    "\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-daf7ecb7-b3ec-453d-a807-d06572e58d31",
    "deepnote_cell_height": 1089,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1650219772312,
    "is_code_hidden": false,
    "source_hash": "79d0de98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decide whether to run through all the cities\n",
    "run = False\n",
    "if run:\n",
    "    # Map to store cities with their vegetation fraction\n",
    "    cities = {}\n",
    "    # Get all cities in the path\n",
    "    city_list = sorted(glob.glob(\"American Cities/*\"))\n",
    "\n",
    "    # Run through all the cities, with progressbar\n",
    "    for city in tqdm(city_list, desc=\"Progress\"):\n",
    "        # Extract city name from filename\n",
    "        city_name = city.split(\"/\")[-1].split(\".json\")[0]\n",
    "        # Get the NDVI image for the city\n",
    "        image_ndvi = get_image(\n",
    "            city, dataset=Dataset.NDVI, bands=Bands.RGBA, stitch_tiles=False\n",
    "        )\n",
    "\n",
    "        # Check if we got a list of image tiles or a single image\n",
    "        if not isinstance(image_ndvi, list):\n",
    "            image_veg_only_hl, veg_frac, weight = vegetation_only_highlighted(\n",
    "                image_ndvi\n",
    "            )\n",
    "            cities[city_name] = veg_frac\n",
    "        else:\n",
    "            # If we got a list of image tiles, we need lists to be able to\n",
    "            # weight the results\n",
    "            fracs = []\n",
    "            weights = []\n",
    "            # Go through each image, with progressbar\n",
    "            for image in tqdm(\n",
    "                image_ndvi,\n",
    "                total=len(image_ndvi),\n",
    "                leave=False,\n",
    "                desc=\"Processing {:s}\".format(city_name),\n",
    "            ):\n",
    "                image_veg_only_hl, veg_frac, weight = vegetation_only_highlighted(image)\n",
    "                fracs.append(veg_frac)\n",
    "                weights.append(weight)\n",
    "\n",
    "            # Find the total weighted vegetation fraction\n",
    "            frac = np.sum(np.multiply(weights, fracs) / np.sum(weights))\n",
    "            cities[city_name] = frac\n",
    "\n",
    "        # Write result to temporary result file, so we don't overwrite the previous final file \n",
    "        # if we spot that something is wrong\n",
    "        with open(\"result_tmp.csv\", \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=\",\")\n",
    "            writer.writerow([\"City\", \"Vegetation Fraction\"])\n",
    "            for key in cities:\n",
    "                writer.writerow([key, cities[key]])\n",
    "    \n",
    "    # Loop is done, write final result to file\n",
    "    with open(\"result.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        writer.writerow([\"City\", \"Vegetation Fraction\"])\n",
    "        for key in cities:\n",
    "            writer.writerow([key, cities[key]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EiT test.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e3de928f-7086-445f-8de4-de81547c7b75",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
